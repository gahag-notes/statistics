\documentclass{article}

\usepackage[margin=1in]{geometry}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{calc}
\usepackage{lmodern}
\usepackage{multirow,multicol}
\usepackage{pgfplots}
\usepackage{qtree}
\usepackage{upgreek}
\usepackage[normalem]{ulem}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[hidelinks]{hyperref}


\newcommand*\diff{\mathop{}\!d}

\newcommand{\Binom}[2]{%
  \left(
    \begin{array}{@{}c@{\,}} #1\\#2 \end{array}
  \right)
}


\begin{document}


\begin{table}[h]
  \begin{tabular}{ll}
    \multicolumn{2}{l}{\hspace{-6pt}\textbf{Conceitos fundamentais}} \\ \midrule
    \multicolumn{2}{l}{A probabilidade é o estudo das experiências aleatórias.} \\[5pt]
    Experimento aleatório & Experimento cujo resultado não pode ser previsto com exatidão. \\[1pt]
    Espaço amostral ($\Omega$) & O conjunto de \uline{todos} os resultados possíveis em uma experiência. \\[1pt]
    Evento & Um subconjunto de $\Omega$. \\[3pt]
    População & Conjunto de \uline{todos} os elementos candidatos à observação \\[1pt]
    Amostra & Parte da população que é observada \\
    Classe & Subdivisão da amostra
  \end{tabular}
\end{table} \vspace{-10pt}



\section{Função Probabilidade}
Uma função probabilidade é uma função do tipo $P:\, \mathcal{P}(\Omega) \to [0, 1]$. \\[5pt]
Propriedades de uma função probabilidade:
\begin{itemize}
  \item $P(\Omega) = 1$,\enspace $P(\varnothing) = 0$
  \item $0 \leq P(A) \leq 1$
  \item $\forall \: A_1, A_2, \hdots, A_n \text{ disjuntos}:\: P\left(\bigcup\limits_{i=1}^{n} A_i\right) = \sum\limits_{i=1}^{n} P(A_i)$
  \item $P(A^c) = 1 - P(A)$
  \item $A \subseteq B \implies P(A) \leq P(B)$
  \item $P(A \cup B) = P(A) + P(B) - P(A \cap B)$
\end{itemize}


\subsection{Probabilidade Clássica}
A função de probabilidade clássica para espaços \uline{equiprováveis} é
\[ P(A) = \frac{\mid A \mid}{\mid \Omega \mid} \]


\subsection{Probabilidade Condicional}
A probabilidade de um evento $B$ acontecer dado um evento $A$ é
\[ P(B|A) = \frac{P(A \cap B)}{P(A)} \] \\
O conjunto de eventos $\{ A_1, \hdots, A_n \}$ forma uma \uline{partição} de $\Omega$ se e somente se
\begin{itemize}
  \item $\forall \, i \neq j: A_i \cap A_j = \varnothing$ \quad (Os eventos são disjuntos entre si)
  \item $\bigcup\limits_{i=1}^{n} A_i = \Omega$
\end{itemize}
\vspace{5pt}
\uline{Teorema da probabilidade total}: Dada uma partição $\{ A_1, \hdots, A_n \}$
\[ P(B) = \sum_{i = 1}^{n} P(A_i) \cdot P(B|A_i) \] \\
\uline{Teorema de Bayes}: Dada uma partição $\{ A_1, \hdots, A_n \}$
% \[ P(B|A) = \frac{P(B)}{P(A)} \cdot P(A|B) \]
\[ P(A_i|B) = \frac{P(B|A_i) \cdot P(A_i)}{\sum\limits_{j=1}^{n} P(B|A_j) \cdot P(A_j)} \]


\subsection{Independência}
Dois eventos $A$ e $B$ são independentes se e somente se
\[ P(A \cap B) = P(A) \cdot P(B) \]
\uline{Corolário}: Se $A$ e $B$ são independentes, então $P(A|B) = P(A)$. \\[10pt]
Isto significa que a ocorrência de um evento não afeta a probabilidade do outro numa mesma amostra. \\
Portanto, eventos disjuntos \uline{não são independentes}, pois não podem ocorrer simultaneamente. \\[10pt]
Propriedade: Se $A$ e $B$ são independentes, então os seguintes conjuntos são independentes entre si:
\begin{itemize}
  \item $A$ e $B^c$
  \item $A^c$ e $B$
  \item $A^c$ e $B^c$
\end{itemize}



\section{Variáveis Aleatórias Quantitativas}
Uma variável aleatória quantitativa é uma função que associa alguma propriedade de um resultado de um experimento aleatório à um número real.
\[ X: \Omega \to \mathbb{R} \]
A imagem de uma variável aleatória $X$ é denotada por $R_X$. \\[5pt]
Se $R_X$ é um conjunto enumerável, dizemos que esta variável é \uline{discreta}. \\
Se $R_X$ é um conjunto não enumerável, dizemos que esta variável é \uline{contínua}. \\[10pt]
A função de probabilidade de uma variável aleatória assumir um valor $c \in \mathbb{R}$ é
\[ P(X = c) \]
Propriedades: \\[5pt]
Se $X$ for uma varíavel aleatória \uline{discreta}:
\begin{itemize}
  \item $\forall\: x_i:\> 0 \leq P(X = x_i) \leq 1$
  \item $\sum\limits_i P(X = x_i) = 1$
\end{itemize}
\vspace{-5pt}
Se $X$ for uma variável aleatória \uline{contínua}:
\begin{multicols}{2}
  \begin{itemize}
    \item $\forall\: a, b:\> 0 \leq P(X \in [a,b\,]) \leq 1$
    \item $\int P(X = x) \diff x = 1$
    \item $P(X = a) = 0$
    \item $P(a \leq X \leq b) = P(a < X < b)$
  \end{itemize}
\end{multicols}


\subsection{Densidade}
Uma variável aleatória $X$ é \uline{contínua} se existe uma função associada $f(x)$ tal que
\begin{align*}
  \forall\, x: f(x) \geq 0& \\
  \int f(x) \diff x = 1&
\end{align*}
Tal função é chamada função de densidade da variável aleatória $X$. \\[10pt]
A função de probabilidade para uma variável aleatória contínua $X$ é
\[ P\big(X \in [a, b\hspace{0.1pt}]\big) = \int\limits_a^b f(x) \diff x \]


\subsection{Distruibuição}
A distribuição de uma variável aleatória é definida por
\[ \left\{ \big( x\,,\: P(X = x) \big) \:\Big|\: x \in R_X \right\} \]
A distribuição portanto define um gráfico em $\mathbb{R}^2$ das probabilidades associadas aos valores que $X$ assume. \\[10pt]
A função de distribuição de uma variável aleatória $X$ é
\begin{align*}
  F(a) =&\> P(X \leq a) \\[10pt]
  \hspace{120px} F(a) =& \sum\limits_{x \in R_X}^{a} P(X = x) && \text{$X$ discreta.} \\[5pt]
  F(a) =& \int\limits_{-\infty}^a f(x) \diff x && \text{$X$ contínua.}
\end{align*}


\subsection{Esperança}
A esperança é uma função que dá o valor esperado de uma variável aleatória. \\[5pt]
Propriedades:
\begin{itemize}
  \item $E(X + Y) = E(X) + E(Y)$
\end{itemize}

\subsubsection{Variável Aleatória Discreta}
Seja $X$ uma variável aleatória com $R_X = \{x_1, \hdots, x_n\}$. \\
A esperança matemática de $X$ é a média dos valores de $R_X$ ponderada pelas suas probabilidades.
\[ E(X) = \sum_{i=1}^{n} x_i \cdot P(X = x_i) \] % \text{$X$ discreto.}
%  & E(X) = \int_{-\infty}^{\infty} x \cdot f(x) \: dx && \text{$X$ contínuo.}
Propriedades:
\begin{itemize}
  \item Se $X = c$, então $E(X) = c \cdot P(X = c) = c$
  \item Se $Y = f(X)$, então $E(Y) = \sum\limits_{i = 1}^{n} f(x_i) \cdot P(X = x_i)$
\end{itemize}

\subsubsection{Variável Aleatória Contínua}
Seja $X$ uma variável aleatória com função de densidade $f(x)$. \\
A esperança de $X$ é dada por
\[ E(X) = \int x \cdot f(x) \> \diff x \]


\pagebreak


\subsection{Variância}
A variância de uma variável aleatória $X$ é
\begin{align*}
  \hspace{80px} \text{var}(X) & = E[{(X - E(X))}^2] && \text{definição clássica de variância} \\
  & = E(X^2) - {E(X)}^2 && \text{fórmula reduzida}
\end{align*}

\subsubsection{Variável Aleatória Discreta}
Seja $X$ uma variável aleatória discreta. \\[5pt]
Propriedades:
\begin{itemize}
  \item Se $X = c$, então $\text{var}(X) = 0$
  \item Se $Y = a \cdot X + b$, então $\text{var}(Y) = a^2 \cdot \text{var}(X)$
\end{itemize}

\subsubsection{Variável Aleatória Contínua}
Seja $X$ uma variável aleatória com função de densidade $f(x)$. \\
\[ E(X^2) = \int x^2 \cdot f(x) \> \diff x\]


\subsection{Desvio Padrão}
O desvio padrão de uma variável aleatória $X$ é
\[ \text{dp}(X) = \sqrt{\text{var}(X)} \]



\section{Modelos Discretos}


\subsection{Modelo Uniforme}
Seja $X$ uma variável aleatória com $R_X = \{ x_1, \hdots, x_n \}$. Dizemos que $X$ segue o modelo uniforme discreto se
\[ \forall\: x \in R_X :\> P(X = x) = \frac{1}{n} \]
Denota-se $X \sim \text{U}\{x_1, \hdots, x_n\}$. \\[10pt]
Propriedades:
\begin{itemize}
  \item $E(X) = \sum\limits_{i=1}^{n} \dfrac{x_i}{n}$
  \item $\text{var}(X) = \dfrac{\sum\limits_{i=1}^{n} {x_i}^2}{n} - {\left( \dfrac{\sum\limits_{i=1}^{n} x_i}{n} \right)}^2$
\end{itemize}


\pagebreak


\subsection{Modelo de Bernoulli}
Seja $X$ uma variável aleatória com $R_X = \{ x_1, x_2 \}$, sendo $x_1$ o sucesso do experimento, e $x_2$ o fracasso. \\
Dizemos que $X$ segue o modelo discreto de Bernoulli com parâmetro $p$ se
\[ 0 < p < 1 \]
\vspace{-20pt}
\begin{align*}
  &P(X = x_1) = p \\
  &P(X = x_2) = 1 - p
\end{align*}
Denota-se $X \sim \text{Ber}(p)$. \\[10pt]
Propriedades:
\begin{itemize}
  \item $E(X) = p$
  \item $\text{var}(X) = p$
\end{itemize}


\subsection{Modelo Binomial}
Seja $X$ uma variável aleatória que conta os sucessos em $n$ experimentos de Bernoulli($p$). \\
A probabilidade de $k$ sucessos é
\[ P(X = k) \>=\> {n \choose k} \cdot p^k \cdot {(1 - p)}^{(n - k)} \]
Denota-se $X \sim \text{Bin}(n,p)$. \\[10pt]
Propriedades:
\begin{itemize}
  \item $E(X) = np$
  \item $\text{var}(X) = np \cdot (1 - p)$
\end{itemize}


\subsection{Modelo Geométrico}
Seja $X$ uma variável aleatória que conta as amostras até o primeiro sucesso em experimentos de Bernoulli($p$). \\
A probabilidade de $k$ amostras até o sucesso é
\[ P(X = k) \>=\> p \cdot {(1 - p)}^{(k - 1)} \]
Denota-se $X \sim \text{Geo}(p)$. \\[10pt]
Propriedades:
\begin{itemize}
  \item $E(X) = \dfrac{1}{p}$
  \item $\text{var}(X) = \dfrac{1 - p}{p^2}$
\end{itemize}


\pagebreak


\subsection{Modelo Binomial Negativo}
Seja $X$ uma variável aleatória que conta os sucessos em experimentos de Bernoulli($p$). \\
A probabilidade de $k$ amostras até se obter $r$ sucessos é
\[ P(X = k) \>=\> {{k -1} \choose {r - 1}} \cdot p^r \cdot {(1 - p)}^{(k - r)} \]
Denota-se $X \sim \text{BN}(r, p)$. \\[10pt]
Propriedades:
\begin{itemize}
  \item $E(X) = \dfrac{r}{p}$
  \item $\text{var}(X) = \dfrac{r \cdot (1 - p)}{p^2}$
\end{itemize}


\subsection{Modelo Hipergeométrico}
Considere $N$ objetos, dos quais $K$ são do tipo $\Gamma$ e os demais de outro tipo. \\
Seja $X$ uma variável aleatória que conta o número de objetos do tipo $\Gamma$ em uma amostra de $n$ objetos. \\
A probabilidade de haver $k$ objetos deste tipo na amostra é
\[ P(X = k) \>=\> \frac{\Binom{K}{k} \cdot \Binom{N - K}{n - k}}{\Binom{N}{n}} \]
Denota-se $X \sim \text{HG}(K, N, n)$. \\[10pt]
Propriedades:
\begin{itemize}
  \item $E(X) = \dfrac{nK}{N}$
  \item $\text{var}(X) = \dfrac{nK}{N} \cdot \left( 1 - \dfrac{nK}{N} \right) \cdot \dfrac{N - n}{N - 1}$
\end{itemize}


\subsection{Modelo de Poisson}
Considere $A$ como um evento de ocorrência independente de si mesmo. \\
Seja $X$ uma variável aleatória que conta as ocorrências de $A$ em um determinado intervalo de tempo. \\
Dizemos que $X$ segue o modelo de Poisson com parâmetro $\lambda$ se
\[ \lambda > 0 \]
\[ P(X = k) \>=\> \frac{e^{-\lambda} \cdot \lambda^k}{k!} \]
Denota-se $X \sim \text{P}(\lambda)$. \\[10pt]
Propriedades:
\begin{itemize}
  \item $E(X) = \lambda$
  \item $\text{var}(X) = \lambda$
\end{itemize}



\section{Modelos Contínuos}


\subsection{Modelo Uniforme}
Seja $X$ uma variável aleatória com função de densidade $f(x)$. \\
Dizemos que $X$ segue o modelo uniforme no intervalo $[a,b\hspace{0.1pt}]$ se sua função de densidade é
\[
  f(x) = \begin{cases}
          \dfrac{1}{b - a} & a \leq x \leq b \\[10pt]
          \hfil 0 & \text{caso contrário}
         \end{cases} \\[10pt]
\]
Denota-se $X \sim \text{U}(a, b)$. \\[10pt]
Propriedades:
\begin{itemize}
  \item $E(X) = \dfrac{a + b}{2}$
  \item $\text{var}(X) = \dfrac{{(b - a)}^2}{12}$
\end{itemize}


\subsection{Modelo Exponencial}
Seja $X$ uma variável aleatória que descreve o tempo decorrido até um evento (normalmente falha/defeito). \\
Dizemos que $X$ segue o modelo exponencial com parâmetro $\lambda$ se
\begin{gather*}
  \lambda > 0 \\[5pt]
  f(x) = \begin{cases}
          \lambda \cdot e^{(-\lambda \cdot x)} &x > 0 \\[10pt]
          \hfil 0 &\text{caso contrário}
         \end{cases}
\end{gather*}
Denota-se $X \sim \text{Exp}(\lambda)$. \\[10pt]
Propriedades:
\begin{itemize}
  \item $E(X) = \dfrac{1}{\lambda}$
  \item $\text{var}(X) = \dfrac{1}{\lambda^2}$
  \item $P\left(X > (s + t) \:\big|\: X > s \right) = P(X > t)$ \quad\qquad perda de memória.
\end{itemize}

\subsection{Modelo Normal}
Seja $X$ uma variável aleatória que modela algum evento natural ou relacionado à natureza. \\
Dizemos que $X$ segue o modelo normal com parâmetros $\mu$ e $\sigma^2$ se
\begin{gather*}
  \sigma^2 > 0 \\[5pt]
  f(x) = \frac{1}{\sigma \cdot \sqrt{2\pi}} \cdot\, \exp \left( -\dfrac{{(x - \mu)}^2}{2 \sigma^2} \right)
\end{gather*}
Denota-se $X \sim \text{N}\left(\mu, \sigma^2\right)$. \\[10pt]
Propriedades:
\begin{itemize}
  \item $E(X) = \mu$
  \item $\text{var}(X) = \sigma^2$
\end{itemize}

\subsubsection{Normal Padrão}
Dizemos que $X$ segue o modelo normal padrão se $X \sim \text{N}\left(0, 1\right)$. \\[10pt]
\uline{Teorema}: Se $X \sim \text{N}\left(\mu, \sigma^2\right)$, então
\[ \left( Z = \frac{X - \mu}{\sigma} \right) \sim \text{N}\left(0, 1\right) \]


\section{Variáveis Aleatórias Qualitativas}
Uma variável aleatória qualitativa é uma função que associa um resultado aleatório a um nome. \\[5pt]
A imagem de uma variável aleatória $X$ é denotada por $R_X$. \\[5pt]
Se $R_X$ é um conjunto ordenável, dizemos que esta variável é \uline{ordinal}. \\
Se $R_X$ é um conjunto \uline{não} ordenável, dizemos que esta variável é \uline{nominal}. \\


\section{Frequências}
\vspace{-10pt}
\begin{table}[h]
  \begin{tabular}{lll}
    \multicolumn{3}{l}{\hspace{-6pt}Frequências de uma classe $i$ em uma amostra de tamanho $n$} \\ \midrule
    Frequência & \makebox[80pt]{\centering $n_i$} & \\[5pt]
    Acumulada  & \makebox[80pt]{\centering $N_i = \sum\limits_{j = 1}^{i} n_j$} & \\[15pt]
    Relativa   & \makebox[80pt]{\centering $f_i = \dfrac{n_i}{n}$} & \\[10pt]
    Relativa acumulada & \makebox[80pt]{\centering $F_i = \sum\limits_{j = 1}^{i} f_j$}
  \end{tabular}
\end{table}
\noindent A curva correspondente ao histograma de frequências relativas acumuladas é denominada \uline{ogiva}. \\[5pt]
A ogiva aproxima a função de distribuição de probabilidade.


\section{Medidas de tendência central}
\vspace{-10pt}
\begin{table}[h]
  \begin{tabular}{ll}
    \multicolumn{2}{l}{\hspace{-6pt}Medidas de tendência central} \\ \midrule
    Média & média aritmética \uline{ponderada} \\[2pt]
    Mediana & valor central, tal que 50\% dos valores são inferiores \\[2pt]
    Primeiro quartil & valor que define um quarto, tal que 25\% dos valores são inferiores \\[2pt]
    Terceiro quartil & valor que define três quartos, tal que 75\% dos valores são inferiores
  \end{tabular}
\end{table}


\end{document}
