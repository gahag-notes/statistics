\documentclass{article}

\usepackage[margin=1in]{geometry}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{calc}
\usepackage{lmodern}
\usepackage{multirow,multicol}
\usepackage{pgfplots}
\usepackage{qtree}
\usepackage{upgreek}
\usepackage[normalem]{ulem}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[hidelinks]{hyperref}


\newcommand*\diff{\mathop{}\!d}

\newcommand{\Binom}[2]{%
  \left(
    \begin{array}{@{}c@{\,}} #1\\#2 \end{array}
  \right)
}


\begin{document}


\begin{table}[h]
  \begin{tabular}{ll}
    \multicolumn{2}{l}{\hspace{-6pt}\textbf{Conceitos fundamentais}} \\ \midrule
    \multicolumn{2}{l}{A probabilidade é o estudo das experiências aleatórias.} \\[5pt]
    Experimento aleatório & Experimento cujo resultado não pode ser previsto com exatidão. \\[1pt]
    Espaço amostral ($\Omega$) & O conjunto de \uline{todos} os resultados possíveis em uma experiência. \\[1pt]
    Evento & Um subconjunto de $\Omega$. \\[1pt]
  \end{tabular}
\end{table} \vspace{-10pt}



\section{Função Probabilidade}
Uma função probabilidade é uma função do tipo $P:\, \mathcal{P}(\Omega) \to [0, 1]$. \\[5pt]
Propriedades de uma função probabilidade:
\begin{itemize}
  \item $P(\Omega) = 1$,\enspace $P(\varnothing) = 0$
  \item $0 \leq P(A) \leq 1$
  \item $\forall \: A_1, A_2, \hdots, A_n \text{ disjuntos}:\: P\left(\bigcup\limits_{i=1}^{n} A_i\right) = \sum\limits_{i=1}^{n} P(A_i)$
  \item $P(A^c) = 1 - P(A)$
  \item $A \subseteq B \implies P(A) \leq P(B)$
  \item $P(A \cup B) = P(A) + P(B) - P(A \cap B)$
\end{itemize}


\subsection{Probabilidade Clássica}
A função de probabilidade clássica para espaços \uline{equiprováveis} é
\[ P(A) = \frac{\mid A \mid}{\mid \Omega \mid} \]


\subsection{Probabilidade Condicional}
A probabilidade de um evento $B$ acontecer dado um evento $A$ é
\[ P(B|A) = \frac{P(A \cap B)}{P(A)} \] \\
O conjunto de eventos $\{ A_1, \hdots, A_n \}$ forma uma \uline{partição} de $\Omega$ se e somente se
\begin{itemize}
  \item $\forall \, i \neq j: A_i \cap A_j = \varnothing$ \quad (Os eventos são disjuntos entre si)
  \item $\bigcup\limits_{i=1}^{n} A_i = \Omega$
\end{itemize}
\vspace{5pt}
\uline{Teorema da probabilidade total}: Dada uma partição $\{ A_1, \hdots, A_n \}$
\[ P(B) = \sum_{i = 1}^{n} P(A_i) \cdot P(B|A_i) \] \\
\uline{Teorema de Bayes}: Dada uma partição $\{ A_1, \hdots, A_n \}$
% \[ P(B|A) = \frac{P(B)}{P(A)} \cdot P(A|B) \]
\[ P(A_i|B) = \frac{P(B|A_i) \cdot P(A_i)}{\sum\limits_{j=1}^{n} P(B|A_j) \cdot P(A_j)} \]


\subsection{Independência}
Dois eventos $A$ e $B$ são independentes se e somente se
\[ P(A \cap B) = P(A) \cdot P(B) \]
\uline{Corolário}: Se $A$ e $B$ são independentes, então $P(A|B) = P(A)$. \\[10pt]
Isto significa que a ocorrência de um evento não afeta a probabilidade do outro numa mesma amostra. \\
Portanto, eventos disjuntos \uline{não são independentes}, pois não podem ocorrer simultaneamente. \\[10pt]
Propriedade: Se $A$ e $B$ são independentes, então os seguintes conjuntos são independentes entre si:
\begin{itemize}
  \item $A$ e $B^c$
  \item $A^c$ e $B$
  \item $A^c$ e $B^c$
\end{itemize}



\section{Variáveis Aleatórias}
Uma variável aleatória é uma função que associa alguma propriedade de um resultado de um experimento aleatório à um número real.
\[ X: \Omega \to \mathbb{R} \]
A imagem de uma variável aleatória $X$ é denotada por $R_X$. \\[5pt]
Se $R_X$ é um conjunto enumerável, dizemos que esta variável é \uline{discreta}. \\
Se $R_X$ é um conjunto não enumerável, dizemos que esta variável é \uline{contínua}. \\[10pt]
A função de probabilidade de uma variável aleatória assumir um valor $c \in \mathbb{R}$ é
\[ P(X = c) \]
Propriedades: \\[5pt]
Se $X$ for uma varíavel aleatória \uline{discreta}:
\begin{itemize}
  \item $\forall\: x_i:\> 0 \leq P(X = x_i) \leq 1$
  \item $\sum\limits_i P(X = x_i) = 1$
\end{itemize}
\vspace{-5pt}
Se $X$ for uma variável aleatória \uline{contínua}:
\begin{multicols}{2}
  \begin{itemize}
    \item $\forall\: a, b:\> 0 \leq P(X \in [a,b\,]) \leq 1$
    \item $\int P(X = x) \diff x = 1$
    \item $P(X = a) = 0$
    \item $P(a \leq X \leq b) = P(a < X < b)$
  \end{itemize}
\end{multicols}


\subsection{Densidade}
Uma variável aleatória $X$ é \uline{contínua} se existe uma função associada $f(x)$ tal que
\begin{align*}
  \forall\, x: f(x) \geq 0& \\
  \int f(x) \diff x = 1&
\end{align*}
Tal função é chamada função de densidade da variável aleatória $X$. \\[10pt]
A função de probabilidade para uma variável aleatória contínua $X$ é
\[ P\big(X \in [a, b\hspace{0.1pt}]\big) = \int\limits_a^b f(x) \diff x \]


\subsection{Distruibuição}
A distribuição de uma variável aleatória é definida por
\[ \left\{ \big( x\,,\: P(X = x) \big) \:\Big|\: x \in R_X \right\} \]
A distribuição portanto define um gráfico em $\mathbb{R}^2$ das probabilidades associadas aos valores que $X$ assume. \\[10pt]
A função de distribuição de uma variável aleatória $X$ é
\begin{align*}
  F(a) =&\> P(X \leq a) \\[10pt]
  \hspace{120px} F(a) =& \sum\limits_{x \in R_X}^{a} P(X = x) && \text{$X$ discreta.} \\[5pt]
  F(a) =& \int\limits_{-\infty}^a f(x) \diff x && \text{$X$ contínua.}
\end{align*}


\subsection{Esperança}
A esperança é uma função que dá o valor esperado de uma variável aleatória. \\[5pt]
Propriedades:
\begin{itemize}
  \item $E(X + Y) = E(X) + E(Y)$
\end{itemize}

\subsubsection{Variável Aleatória Discreta}
Seja $X$ uma variável aleatória com $R_X = \{x_1, \hdots, x_n\}$. \\
A esperança matemática de $X$ é a média dos valores de $R_X$ ponderada pelas suas probabilidades.
\[ E(X) = \sum_{i=1}^{n} x_i \cdot P(X = x_i) \] % \text{$X$ discreto.}
%  & E(X) = \int_{-\infty}^{\infty} x \cdot f(x) \: dx && \text{$X$ contínuo.}
Propriedades:
\begin{itemize}
  \item Se $X = c$, então $E(X) = c \cdot P(X = c) = c$
  \item Se $Y = f(X)$, então $E(Y) = \sum\limits_{i = 1}^{n} f(x_i) \cdot P(X = x_i)$
\end{itemize}

\subsubsection{Variável Aleatória Contínua}
Seja $X$ uma variável aleatória com função de densidade $f(x)$. \\
A esperança de $X$ é dada por
\[ E(X) = \int x \cdot f(x) \> \diff x \]


\pagebreak


\subsection{Variância}
A variância de uma variável aleatória $X$ é
\begin{align*}
  \hspace{80px} \text{var}(X) & = E[{(X - E(X))}^2] && \text{definição clássica de variância} \\
  & = E(X^2) - {E(X)}^2 && \text{fórmula reduzida}
\end{align*}

\subsubsection{Variável Aleatória Discreta}
Seja $X$ uma variável aleatória discreta. \\[5pt]
Propriedades:
\begin{itemize}
  \item Se $X = c$, então $\text{var}(X) = 0$
  \item Se $Y = a \cdot X + b$, então $\text{var}(Y) = a^2 \cdot \text{var}(X)$
\end{itemize}

\subsubsection{Variável Aleatória Contínua}
Seja $X$ uma variável aleatória com função de densidade $f(x)$. \\
\[ E(X^2) = \int x^2 \cdot f(x) \> \diff x\]


\subsection{Desvio Padrão}
O desvio padrão de uma variável aleatória $X$ é
\[ \text{dp}(X) = \sqrt{\text{var}(X)} \]



\section{Modelos Discretos}


\subsection{Modelo Uniforme}
Seja $X$ uma variável aleatória com $R_X = \{ x_1, \hdots, x_n \}$. Dizemos que $X$ segue o modelo uniforme discreto se
\[ \forall\: x \in R_X :\> P(X = x) = \frac{1}{n} \]
Denota-se $X \sim U\{x_1, \hdots, x_n\}$. \\[10pt]
Propriedades:
\begin{itemize}
  \item $E(X) = \sum\limits_{i=1}^{n} \dfrac{x_i}{n}$
  \item $\text{var}(X) = \dfrac{\sum\limits_{i=1}^{n} {x_i}^2}{n} - {\left( \dfrac{\sum\limits_{i=1}^{n} x_i}{n} \right)}^2$
\end{itemize}


\pagebreak


\subsection{Modelo de Bernoulli}
Seja $X$ uma variável aleatória com $R_X = \{ x_1, x_2 \}$, sendo $x_1$ o sucesso do experimento, e $x_2$ o fracasso. \\
Dizemos que $X$ segue o modelo discreto de Bernoulli com parâmetro $p$ se
\[ 0 < p < 1 \]
\vspace{-20pt}
\begin{align*}
  &P(X = x_1) = p \\
  &P(X = x_2) = 1 - p
\end{align*}
Denota-se $X \sim \text{Ber}(p)$. \\[10pt]
Propriedades:
\begin{itemize}
  \item $E(X) = p$
  \item $\text{var}(X) = p$
\end{itemize}


\subsection{Modelo Binomial}
Seja $X$ uma variável aleatória que conta os sucessos em $n$ experimentos de Bernoulli($p$). \\
A probabilidade de $k$ sucessos é
\[ P(X = k) \>=\> {n \choose k} \cdot p^k \cdot {(1 - p)}^{(n - k)} \]
Denota-se $X \sim \text{Bin}(n,p)$. \\[10pt]
Propriedades:
\begin{itemize}
  \item $E(X) = np$
  \item $\text{var}(X) = np \cdot (1 - p)$
\end{itemize}


\subsection{Modelo Geométrico}
Seja $X$ uma variável aleatória que conta as amostras até o primeiro sucesso em experimentos de Bernoulli($p$). \\
A probabilidade de $k$ amostras até o sucesso é
\[ P(X = k) \>=\> p \cdot {(1 - p)}^{(k - 1)} \]
Denota-se $X \sim \text{Geo}(p)$. \\[10pt]
Propriedades:
\begin{itemize}
  \item $E(X) = \dfrac{1}{p}$
  \item $\text{var}(X) = \dfrac{1 - p}{p^2}$
\end{itemize}


\pagebreak


\subsection{Modelo Binomial Negativo}
Seja $X$ uma variável aleatória que conta os sucessos em experimentos de Bernoulli($p$). \\
A probabilidade de $k$ amostras até se obter $r$ sucessos é
\[ P(X = k) \>=\> {{k -1} \choose {r - 1}} \cdot p^r \cdot {(1 - p)}^{(k - r)} \]
Denota-se $X \sim \text{BN}(r, p)$. \\[10pt]
Propriedades:
\begin{itemize}
  \item $E(X) = \dfrac{r}{p}$
  \item $\text{var}(X) = \dfrac{r \cdot (1 - p)}{p^2}$
\end{itemize}


\subsection{Modelo Hipergeométrico}
Considere $N$ objetos, dos quais $K$ são do tipo $\Gamma$ e os demais de outro tipo. \\
Seja $X$ uma variável aleatória que conta o número de objetos do tipo $\Gamma$ em uma amostra de $n$ objetos. \\
A probabilidade de haver $k$ objetos deste tipo na amostra é
\[ P(X = k) \>=\> \frac{\Binom{K}{k} \cdot \Binom{N - K}{n - k}}{\Binom{N}{n}} \]
Denota-se $X \sim \text{HG}(K, N, n)$. \\[10pt]
Propriedades:
\begin{itemize}
  \item $E(X) = \dfrac{nK}{N}$
  \item $\text{var}(X) = \dfrac{nK}{N} \cdot \left( 1 - \dfrac{nK}{N} \right) \cdot \dfrac{N - n}{N - 1}$
\end{itemize}


\subsection{Modelo de Poisson}
Seja $X$ uma variável aleatória tendo como imagem o conjunto $\mathbb{N}$. \\
Dizemos que $X$ segue o modelo de Poisson com parâmetro $\lambda$ se
\[ \lambda > 0 \]
\[ P(X = k) \>=\> \frac{e^{-\lambda} \cdot \lambda^k}{k!} \]
Denota-se $X \sim \text{P}(\lambda)$. \\[10pt]
Propriedades:
\begin{itemize}
  \item $E(X) = \lambda$
  \item $\text{var}(X) = \lambda$
\end{itemize}



\section{Modelos Contínuos}

\subsection{Modelo Uniforme}
Seja $X$ uma variável aleatória contínua com função de densidade $f(x)$. \\
Dizemos que $X$ segue o modelo uniforme no intervalo $[a,b\hspace{0.1pt}]$ se sua função de densidade é
\[
  f(x) = \begin{cases}
          \dfrac{1}{b - a} \quad a \leq x \leq b \\[10pt]
          \quad 0 \qquad \text{caso contrário}
         \end{cases} \\[10pt]
\]
Denota-se $X \sim U(a, b)$. \\[10pt]
Propriedades:
\begin{itemize}
  \item $E(X) = \dfrac{a + b}{2}$
  \item $\text{var}(X) = \dfrac{{(b - a)}^2}{12}$
\end{itemize}

%% old --------------------------------------------------------------------
\vspace{10pt}\hrule

\section{Famílias de Eventos}
Uma família de eventos é um conjunto de eventos. \\
A maior família de eventos é o conjunto potência de $\Omega$, denotado $\mathcal{P}(\Omega)$. \\[5pt]
Propriedades das famílias de eventos:
\begin{itemize}
  \item $\Omega \in \mathcal{F}$
  \item $A \in \mathcal{F} \implies A^c \in \mathcal{F}$
  \item $A, B \in \mathcal{F} \implies (A \cup B) \in \mathcal{F}$
\end{itemize}



\section{Espaço de Probabilidade}
Um espaço de probabilidade é uma tripla da forma $(\Omega, \mathcal{F}, P)$. \\
O espaço é associado à uma experiência aleatória.


\subsection{Espaços Equiprováveis}
Um espaço de probabilidade $(\Omega, \mathcal{F}, P)$ é equiprovável quando
\[ \forall \, a, b \in \Omega: \> P({a}) = P({b}) = \frac{1}{\mid \Omega \mid} \]


% var aleatoria
% distrib

\section{Densidade}
A probabilidade de uma variável \uline{contínua} estar em um invervalo $[a,b]$ é
\[ P(a \leq X \leq b) = \int_b^a f(x) dx, \qquad f: \mathbb{R} \to \mathbb{R}^+ \]
onde $f$ é a função de densidade de probabilidade associada a $X$. \\[10pt]
Uma função de densidade de probabilidade satisfaz as propriedades:
\begin{itemize}
  \item $\forall\, x \in \mathbb{R}: f(x) \geq 0$.
  \item $\int\limits_{-\infty}^{\infty} f(x) dx = 1$.
\end{itemize}
\uline{Teorema}: Para qualquer distribuição, a probabilidade de uma variável aleatória estar em um intervalo é
\[ P(m \leq x \leq n) = f(n) - f(m) \]

\subsection{Distribuição Uniforme}
A função densidade para uma ditribuição uniforme é
\[
  f(x) = \begin{cases}
          \dfrac{1}{\omega} \quad 0 \leq x \leq \omega \\[10pt]
          0 \quad \text{caso contrário}
         \end{cases}
\]
Já para uma distribuição uniforme reduzida a um intervalo $[a,b] \subset \mathbb{R}$
\[
  f(x) = \begin{cases}
          \dfrac{1}{b - a} \quad a \leq x \leq b \\[10pt]
          0 \qquad \text{caso contrário}
         \end{cases} \\[10pt]
\]

% esperança
% variancia
% dp

\section{Densidade Normal Geral}
\begin{gather*}
  X \sim N(\mu, \sigma^2) \\[5pt]
  f(x) = \frac{1}{\sqrt{2 \pi \sigma^2}} \cdot \exp \left(- \frac{{(x - u)}^2}{2\sigma^2} \right)
\end{gather*}



\end{document}
